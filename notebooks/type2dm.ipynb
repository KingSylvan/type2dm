{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VXuxdTq521vC"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFlKXSdx44fn",
        "outputId": "d7fb93b1-4de8-4459-ca83-b613183ee763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "# Setup and installations - Enhanced\n",
        "!pip install -q lightgbm==4.3.0 xgboost optuna==3.6.0 cmake\n",
        "!apt-get -qq update && apt-get -qq install -y plink\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "import sys\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (classification_report, roc_auc_score, roc_curve,\n",
        "                           precision_recall_curve, average_precision_score, brier_score_loss, f1_score)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "from sklearn.inspection import partial_dependence, PartialDependenceDisplay\n",
        "\n",
        "# Enhanced imports\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rxYT591G44cR"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohOWJYCE44Zm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uegUIncT21yb",
        "outputId": "daf1591d-8116-4db8-cb02-40ab56934c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚¨áÔ∏è  Downloading integer_no_arrays.tsv\n",
            "    ‚úÖ integer_no_arrays.tsv downloaded\n",
            "‚¨áÔ∏è  Downloading integer_diet_quest_fields.tsv\n",
            "    ‚úÖ integer_diet_quest_fields.tsv downloaded\n",
            "‚¨áÔ∏è  Downloading integer_other_quest_fields.tsv\n",
            "    ‚úÖ integer_other_quest_fields.tsv downloaded\n",
            "‚¨áÔ∏è  Downloading real_fields1.tsv\n",
            "    ‚úÖ real_fields1.tsv downloaded\n",
            "‚¨áÔ∏è  Downloading real_fields2.tsv\n",
            "    ‚úÖ real_fields2.tsv downloaded\n",
            "‚¨áÔ∏è  Downloading string_fields1.tsv\n",
            "    ‚úÖ string_fields1.tsv downloaded\n",
            "üìä All data files ready\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Data download configuration (unchanged)\n",
        "BASE = \"https://biobank.ndph.ox.ac.uk/synthetic_dataset/tabular/\"\n",
        "files_to_fetch = {\n",
        "    \"integer_no_arrays.tsv\": BASE + \"integer_no_arrays.tsv\",\n",
        "    \"integer_diet_quest_fields.tsv\": BASE + \"integer_diet_quest_fields.tsv\",\n",
        "    \"integer_other_quest_fields.tsv\": BASE + \"integer_other_quest_fields.tsv\",\n",
        "    \"real_fields1.tsv\": BASE + \"real_fields1.tsv\",\n",
        "    \"real_fields2.tsv\": BASE + \"real_fields2.tsv\",\n",
        "    \"string_fields1.tsv\": BASE + \"string_fields1.tsv\",\n",
        "}\n",
        "\n",
        "DATA_DIR = Path(\"/content/ukb_syn\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def fetch_data(url, out_path):\n",
        "    \"\"\"Download data files if they don't exist\"\"\"\n",
        "    if out_path.exists():\n",
        "        return\n",
        "    print(f\"‚¨áÔ∏è  Downloading {out_path.name}\")\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as r, open(out_path, \"wb\") as f:\n",
        "            f.write(r.read())\n",
        "        print(f\"    ‚úÖ {out_path.name} downloaded\")\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Error downloading {out_path.name}: {e}\")\n",
        "\n",
        "# Download all required files\n",
        "for fname, url in files_to_fetch.items():\n",
        "    fetch_data(url, DATA_DIR / fname)\n",
        "\n",
        "print(\"üìä All data files ready\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UZx30Hssh2tK"
      },
      "outputs": [],
      "source": [
        "FIELD_MAP = {\n",
        "    \"31\": \"sex\",\n",
        "    \"21003\": \"age\",\n",
        "    \"21001\": \"bmi\",\n",
        "    \"48\": \"waist\",\n",
        "    \"1558\": \"alcohol_freq\",\n",
        "    \"20116\": \"smoking_status\",\n",
        "    \"1160\": \"sleep_hrs\",\n",
        "    \"874\": \"vigorous_mins\",\n",
        "    \"864\": \"moderate_mins\",\n",
        "    \"1309\": \"fruit_intake\",\n",
        "    \"1319\": \"veg_intake\",\n",
        "    \"1349\": \"red_meat_intake\",\n",
        "    \"22009\": \"PC\",  # Principal components for ancestry\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eN-jzr7HeJLL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_wanted_columns(header):\n",
        "    \"\"\"Extract relevant columns based on field IDs\"\"\"\n",
        "    import re\n",
        "    keep = set()\n",
        "    for field_id in FIELD_MAP:\n",
        "        pattern = re.compile(rf\"^{field_id}-0\\.\\d+$\")\n",
        "        keep.update([c for c in header if pattern.match(c)])\n",
        "    return keep | {\"eid\"}\n",
        "\n",
        "def load_and_process_data():\n",
        "    \"\"\"Load and merge all TSV files\"\"\"\n",
        "    print(\"üìà Loading and processing data...\")\n",
        "\n",
        "    frames = []\n",
        "    for tfile in DATA_DIR.glob(\"*.tsv\"):\n",
        "        try:\n",
        "            header = pd.read_csv(tfile, nrows=0, sep=\"\\t\").columns\n",
        "            wanted_cols = get_wanted_columns(header)\n",
        "\n",
        "            if len(wanted_cols) > 1:\n",
        "                rename_dict = {}\n",
        "                for col in wanted_cols:\n",
        "                    if col == \"eid\":\n",
        "                        continue\n",
        "                    field_id = col.split('-')[0]\n",
        "                    if field_id == \"22009\":\n",
        "                        pc_num = int(col.split('.')[-1]) + 1\n",
        "                        rename_dict[col] = f\"PC{pc_num}\"\n",
        "                    else:\n",
        "                        rename_dict[col] = FIELD_MAP.get(field_id, col)\n",
        "\n",
        "                df = pd.read_csv(tfile, sep=\"\\t\", usecols=wanted_cols)\n",
        "                df = df.set_index(\"eid\").rename(columns=rename_dict)\n",
        "                frames.append(df)\n",
        "                print(f\"    ‚úÖ Processed {tfile.name}: {df.shape}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ö†Ô∏è  Error processing {tfile.name}: {e}\")\n",
        "\n",
        "    if frames:\n",
        "        phenotype_data = pd.concat(frames, axis=1, join=\"inner\").reset_index()\n",
        "        print(f\"üìä Combined dataset shape: {phenotype_data.shape}\")\n",
        "        return phenotype_data\n",
        "    else:\n",
        "        raise ValueError(\"No data frames were successfully loaded\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4Ps-tYgsh38z"
      },
      "outputs": [],
      "source": [
        "CATEGORY_MAPPINGS = {\n",
        "    'sex': {0: 'Female', 1: 'Male'},\n",
        "    'smoking_status': {0: 'Never', 1: 'Previous', 2: 'Current', 3: 'Unknown'},\n",
        "    'alcohol_freq': {\n",
        "        1: 'Daily', 2: 'Weekly_3_4', 3: 'Weekly_1_2',\n",
        "        4: 'Monthly', 5: 'Occasional', 6: 'Never', 0: 'Unknown'\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Exploration and Visualization Functions\n",
        "\n",
        "def explore_dataset(df):\n",
        "    \"\"\"Comprehensive data exploration\"\"\"\n",
        "    print(\"\\n=== Dataset Overview ===\")\n",
        "    print(f\"Total samples: {len(df)}\")\n",
        "    print(\"\\nMissing Values Summary:\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df) * 100).round(2)\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Count': missing,\n",
        "        'Missing %': missing_pct\n",
        "    }).query('`Missing Count` > 0')\n",
        "    print(missing_df)\n",
        "    \n",
        "    print(\"\\nNumerical Variables Summary:\")\n",
        "    print(df.describe().round(2))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def plot_distributions(df):\n",
        "    \"\"\"Plot distributions of key variables\"\"\"\n",
        "    # Set up the plotting style\n",
        "    plt.style.use('seaborn')\n",
        "    \n",
        "    # Create a figure with multiple subplots\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    \n",
        "    # 1. Age Distribution\n",
        "    plt.subplot(3, 3, 1)\n",
        "    sns.histplot(data=df, x='age', bins=30)\n",
        "    plt.title('Age Distribution')\n",
        "    plt.axvline(df['age'].mean(), color='r', linestyle='--', label=f'Mean: {df[\"age\"].mean():.1f}')\n",
        "    plt.legend()\n",
        "    \n",
        "    # 2. BMI Distribution\n",
        "    plt.subplot(3, 3, 2)\n",
        "    sns.histplot(data=df, x='bmi', bins=30)\n",
        "    plt.title('BMI Distribution')\n",
        "    plt.axvline(25, color='g', linestyle='--', label='Overweight threshold')\n",
        "    plt.axvline(30, color='r', linestyle='--', label='Obese threshold')\n",
        "    plt.legend()\n",
        "    \n",
        "    # 3. Sex Distribution\n",
        "    plt.subplot(3, 3, 3)\n",
        "    sex_counts = df['sex'].map({0: 'Female', 1: 'Male'}).value_counts()\n",
        "    plt.pie(sex_counts.values, labels=sex_counts.index, autopct='%1.1f%%')\n",
        "    plt.title('Sex Distribution')\n",
        "    \n",
        "    # 4. Physical Activity\n",
        "    plt.subplot(3, 3, 4)\n",
        "    total_activity = df['moderate_mins'] + df['vigorous_mins'] * 2\n",
        "    sns.histplot(data=total_activity[total_activity < 1000], bins=30)\n",
        "    plt.title('Total Physical Activity (MET-minutes)')\n",
        "    plt.axvline(150, color='g', linestyle='--', label='WHO Recommendation')\n",
        "    plt.legend()\n",
        "    \n",
        "    # 5. Sleep Hours\n",
        "    plt.subplot(3, 3, 5)\n",
        "    sns.histplot(data=df, x='sleep_hrs', bins=30)\n",
        "    plt.title('Sleep Hours Distribution')\n",
        "    plt.axvline(7, color='g', linestyle='--', label='Recommended min')\n",
        "    plt.axvline(9, color='r', linestyle='--', label='Recommended max')\n",
        "    plt.legend()\n",
        "    \n",
        "    # 6. Smoking Status\n",
        "    plt.subplot(3, 3, 6)\n",
        "    smoking_counts = df['smoking_status'].map({\n",
        "        0: 'Never', 1: 'Previous', 2: 'Current', 3: 'Unknown'\n",
        "    }).value_counts()\n",
        "    plt.bar(smoking_counts.index, smoking_counts.values)\n",
        "    plt.title('Smoking Status Distribution')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # 7. Alcohol Frequency\n",
        "    plt.subplot(3, 3, 7)\n",
        "    alcohol_counts = df['alcohol_freq'].map({\n",
        "        1: 'Daily', 2: 'Weekly_3_4', 3: 'Weekly_1_2',\n",
        "        4: 'Monthly', 5: 'Occasional', 6: 'Never', 0: 'Unknown'\n",
        "    }).value_counts()\n",
        "    plt.bar(alcohol_counts.index, alcohol_counts.values)\n",
        "    plt.title('Alcohol Consumption Frequency')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # 8. Diet (Fruit & Veg)\n",
        "    plt.subplot(3, 3, 8)\n",
        "    total_fruit_veg = df['fruit_intake'] + df['veg_intake']\n",
        "    sns.histplot(data=total_fruit_veg[total_fruit_veg < 50], bins=30)\n",
        "    plt.title('Total Fruit & Vegetable Intake')\n",
        "    plt.axvline(5, color='g', linestyle='--', label='5-a-day target')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_correlations(df):\n",
        "    \"\"\"Plot correlation heatmap of numerical variables\"\"\"\n",
        "    # Select numerical columns\n",
        "    num_cols = ['age', 'bmi', 'waist', 'sleep_hrs', 'vigorous_mins', \n",
        "                'moderate_mins', 'fruit_intake', 'veg_intake']\n",
        "    \n",
        "    # Calculate correlations\n",
        "    corr = df[num_cols].corr()\n",
        "    \n",
        "    # Create heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', center=0,\n",
        "                fmt='.2f', square=True)\n",
        "    plt.title('Correlation Matrix of Key Variables')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_risk_factors(df):\n",
        "    \"\"\"Analyze T2DM risk factors\"\"\"\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # 1. BMI vs T2DM\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.boxplot(x='t2dm_event', y='bmi', data=df)\n",
        "    plt.title('BMI Distribution by T2DM Status')\n",
        "    plt.xlabel('T2DM Status (0=No, 1=Yes)')\n",
        "    \n",
        "    # 2. Age vs T2DM\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.boxplot(x='t2dm_event', y='age', data=df)\n",
        "    plt.title('Age Distribution by T2DM Status')\n",
        "    plt.xlabel('T2DM Status (0=No, 1=Yes)')\n",
        "    \n",
        "    # 3. Physical Activity vs T2DM\n",
        "    plt.subplot(2, 2, 3)\n",
        "    total_activity = df['moderate_mins'] + df['vigorous_mins'] * 2\n",
        "    activity_t2dm = pd.DataFrame({\n",
        "        'T2DM': df['t2dm_event'],\n",
        "        'Total Activity': total_activity\n",
        "    })\n",
        "    sns.boxplot(x='T2DM', y='Total Activity', data=activity_t2dm)\n",
        "    plt.title('Physical Activity by T2DM Status')\n",
        "    plt.xlabel('T2DM Status (0=No, 1=Yes)')\n",
        "    \n",
        "    # 4. Lifestyle Score vs T2DM\n",
        "    plt.subplot(2, 2, 4)\n",
        "    sns.boxplot(x='t2dm_event', y='lifestyle_score', data=df)\n",
        "    plt.title('Lifestyle Score by T2DM Status')\n",
        "    plt.xlabel('T2DM Status (0=No, 1=Yes)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_lifestyle_patterns(df):\n",
        "    \"\"\"Analyze and visualize lifestyle patterns\"\"\"\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # 1. Physical Activity vs Sleep\n",
        "    plt.subplot(2, 2, 1)\n",
        "    total_activity = df['moderate_mins'] + df['vigorous_mins'] * 2\n",
        "    plt.scatter(df['sleep_hrs'], total_activity, alpha=0.1)\n",
        "    plt.title('Physical Activity vs Sleep Hours')\n",
        "    plt.xlabel('Sleep Hours')\n",
        "    plt.ylabel('Total Physical Activity (MET-minutes)')\n",
        "    \n",
        "    # 2. BMI vs Physical Activity\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.scatter(total_activity, df['bmi'], alpha=0.1)\n",
        "    plt.title('BMI vs Physical Activity')\n",
        "    plt.xlabel('Total Physical Activity (MET-minutes)')\n",
        "    plt.ylabel('BMI')\n",
        "    \n",
        "    # 3. Diet Quality\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.scatter(df['fruit_intake'], df['veg_intake'], alpha=0.1)\n",
        "    plt.title('Fruit vs Vegetable Intake')\n",
        "    plt.xlabel('Fruit Intake (portions)')\n",
        "    plt.ylabel('Vegetable Intake (portions)')\n",
        "    \n",
        "    # 4. Age vs Lifestyle Score\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.scatter(df['age'], df['lifestyle_score'], alpha=0.1)\n",
        "    plt.title('Age vs Lifestyle Score')\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Lifestyle Score')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the exploration and visualization\n",
        "print(\"Starting comprehensive data exploration and visualization...\")\n",
        "df_explored = explore_dataset(df)\n",
        "plot_distributions(df_explored)\n",
        "plot_correlations(df_explored)\n",
        "analyze_risk_factors(df_explored)\n",
        "plot_lifestyle_patterns(df_explored)\n",
        "print(\"Data exploration complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical Analysis and Risk Factor Assessment\n",
        "\n",
        "def analyze_risk_groups(df):\n",
        "    \"\"\"Analyze T2DM risk across different demographic and lifestyle groups\"\"\"\n",
        "    print(\"\\n=== T2DM Risk Analysis ===\")\n",
        "    \n",
        "    # 1. Age Groups\n",
        "    df['age_group'] = pd.cut(df['age'], \n",
        "                            bins=[0, 45, 50, 55, 60, 65, 100],\n",
        "                            labels=['<45', '45-50', '50-55', '55-60', '60-65', '65+'])\n",
        "    \n",
        "    age_risk = df.groupby('age_group')['t2dm_event'].agg(['mean', 'count'])\n",
        "    age_risk['mean'] = (age_risk['mean'] * 100).round(2)\n",
        "    print(\"\\nT2DM Risk by Age Group:\")\n",
        "    print(age_risk)\n",
        "    \n",
        "    # 2. BMI Categories\n",
        "    df['bmi_category'] = pd.cut(df['bmi'],\n",
        "                               bins=[0, 18.5, 25, 30, 100],\n",
        "                               labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "    \n",
        "    bmi_risk = df.groupby('bmi_category')['t2dm_event'].agg(['mean', 'count'])\n",
        "    bmi_risk['mean'] = (bmi_risk['mean'] * 100).round(2)\n",
        "    print(\"\\nT2DM Risk by BMI Category:\")\n",
        "    print(bmi_risk)\n",
        "    \n",
        "    # 3. Lifestyle Score Groups\n",
        "    df['lifestyle_group'] = pd.qcut(df['lifestyle_score'], q=4, \n",
        "                                  labels=['Poor', 'Fair', 'Good', 'Excellent'])\n",
        "    \n",
        "    lifestyle_risk = df.groupby('lifestyle_group')['t2dm_event'].agg(['mean', 'count'])\n",
        "    lifestyle_risk['mean'] = (lifestyle_risk['mean'] * 100).round(2)\n",
        "    print(\"\\nT2DM Risk by Lifestyle Score:\")\n",
        "    print(lifestyle_risk)\n",
        "    \n",
        "    # Visualize the risk patterns\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    \n",
        "    # Age groups\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.bar(age_risk.index, age_risk['mean'])\n",
        "    plt.title('T2DM Risk by Age Group')\n",
        "    plt.xlabel('Age Group')\n",
        "    plt.ylabel('Risk (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # BMI categories\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.bar(bmi_risk.index, bmi_risk['mean'])\n",
        "    plt.title('T2DM Risk by BMI Category')\n",
        "    plt.xlabel('BMI Category')\n",
        "    plt.ylabel('Risk (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Lifestyle score\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.bar(lifestyle_risk.index, lifestyle_risk['mean'])\n",
        "    plt.title('T2DM Risk by Lifestyle Score')\n",
        "    plt.xlabel('Lifestyle Score Group')\n",
        "    plt.ylabel('Risk (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return df\n",
        "\n",
        "def analyze_combined_risk_factors(df):\n",
        "    \"\"\"Analyze interaction between multiple risk factors\"\"\"\n",
        "    # Create a pivot table of BMI category and lifestyle score\n",
        "    risk_matrix = pd.pivot_table(df, \n",
        "                                values='t2dm_event',\n",
        "                                index='bmi_category',\n",
        "                                columns='lifestyle_group',\n",
        "                                aggfunc='mean')\n",
        "    \n",
        "    # Visualize the interaction\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(risk_matrix * 100, annot=True, fmt='.1f', cmap='YlOrRd')\n",
        "    plt.title('T2DM Risk (%) by BMI and Lifestyle Score')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Analyze physical activity patterns\n",
        "    activity_groups = pd.qcut(df['moderate_mins'] + df['vigorous_mins'] * 2, \n",
        "                            q=4, labels=['Low', 'Moderate', 'High', 'Very High'])\n",
        "    \n",
        "    activity_bmi_risk = pd.pivot_table(df,\n",
        "                                     values='t2dm_event',\n",
        "                                     index='bmi_category',\n",
        "                                     columns=activity_groups,\n",
        "                                     aggfunc='mean')\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(activity_bmi_risk * 100, annot=True, fmt='.1f', cmap='YlOrRd')\n",
        "    plt.title('T2DM Risk (%) by BMI and Physical Activity Level')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def calculate_risk_metrics(df):\n",
        "    \"\"\"Calculate various risk metrics and statistics\"\"\"\n",
        "    print(\"\\n=== Risk Factor Analysis ===\")\n",
        "    \n",
        "    # Calculate odds ratios for key risk factors\n",
        "    def calculate_odds_ratio(factor, threshold):\n",
        "        high_risk = df[df[factor] >= threshold]['t2dm_event'].mean()\n",
        "        low_risk = df[df[factor] < threshold]['t2dm_event'].mean()\n",
        "        odds_ratio = (high_risk / (1 - high_risk)) / (low_risk / (1 - low_risk))\n",
        "        return odds_ratio\n",
        "    \n",
        "    risk_factors = {\n",
        "        'bmi': 30,  # Obesity threshold\n",
        "        'age': 60,  # Age threshold\n",
        "        'waist': 102,  # High waist circumference threshold\n",
        "        'lifestyle_score': df['lifestyle_score'].median()  # Median lifestyle score\n",
        "    }\n",
        "    \n",
        "    print(\"\\nOdds Ratios for Risk Factors:\")\n",
        "    for factor, threshold in risk_factors.items():\n",
        "        odds_ratio = calculate_odds_ratio(factor, threshold)\n",
        "        print(f\"{factor} (threshold: {threshold}): {odds_ratio:.2f}\")\n",
        "    \n",
        "    # Calculate population attributable risk for obesity\n",
        "    total_risk = df['t2dm_event'].mean()\n",
        "    normal_weight_risk = df[df['bmi'] < 25]['t2dm_event'].mean()\n",
        "    par = (total_risk - normal_weight_risk) / total_risk * 100\n",
        "    \n",
        "    print(f\"\\nPopulation Attributable Risk for Obesity: {par:.1f}%\")\n",
        "\n",
        "# Run the additional analyses\n",
        "print(\"Performing detailed risk analysis...\")\n",
        "df_with_groups = analyze_risk_groups(df_explored)\n",
        "analyze_combined_risk_factors(df_with_groups)\n",
        "calculate_risk_metrics(df_with_groups)\n",
        "print(\"Risk analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Performance Visualization and Interpretation\n",
        "\n",
        "def plot_model_performance_comparison(results):\n",
        "    \"\"\"Visualize and compare model performances\"\"\"\n",
        "    metrics = ['auc', 'f1']\n",
        "    model_names = list(results.keys())\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Plot AUC-ROC comparison\n",
        "    plt.subplot(1, 2, 1)\n",
        "    auc_scores = [results[model]['auc'] for model in model_names]\n",
        "    plt.bar(model_names, auc_scores)\n",
        "    plt.title('AUC-ROC Scores by Model')\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel('AUC-ROC')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Plot F1 scores comparison\n",
        "    plt.subplot(1, 2, 2)\n",
        "    f1_scores = [results[model]['f1'] for model in model_names]\n",
        "    plt.bar(model_names, f1_scores)\n",
        "    plt.title('F1 Scores by Model')\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc_curves(results, X_test, y_test):\n",
        "    \"\"\"Plot ROC curves for all models\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    for name, result in results.items():\n",
        "        fpr, tpr, _ = roc_curve(y_test, result['prob'])\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {result[\"auc\"]:.3f})')\n",
        "    \n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves for All Models')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "def analyze_feature_importance(results, feature_names):\n",
        "    \"\"\"Analyze and visualize feature importance\"\"\"\n",
        "    # Get the best model\n",
        "    best_model_name = max(results.keys(), key=lambda k: results[k]['auc'])\n",
        "    best_model = results[best_model_name]['pipeline'].named_steps['clf']\n",
        "    \n",
        "    # Get feature importance (if available)\n",
        "    if hasattr(best_model, 'feature_importances_'):\n",
        "        importance = best_model.feature_importances_\n",
        "        \n",
        "        # Sort features by importance\n",
        "        feature_imp = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': importance\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        \n",
        "        # Plot feature importance\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.barplot(data=feature_imp.head(15), x='importance', y='feature')\n",
        "        plt.title(f'Top 15 Most Important Features ({best_model_name})')\n",
        "        plt.xlabel('Feature Importance')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"\\nTop 10 Most Important Features:\")\n",
        "        print(feature_imp.head(10))\n",
        "\n",
        "def analyze_prediction_thresholds(results, y_test):\n",
        "    \"\"\"Analyze the effect of different prediction thresholds\"\"\"\n",
        "    # Get the best model\n",
        "    best_model_name = max(results.keys(), key=lambda k: results[k]['auc'])\n",
        "    best_probs = results[best_model_name]['prob']\n",
        "    \n",
        "    thresholds = np.arange(0.1, 0.9, 0.1)\n",
        "    metrics = []\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "        preds = (best_probs >= threshold).astype(int)\n",
        "        precision = precision_score(y_test, preds)\n",
        "        recall = recall_score(y_test, preds)\n",
        "        f1 = f1_score(y_test, preds)\n",
        "        \n",
        "        metrics.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "    \n",
        "    metrics_df = pd.DataFrame(metrics)\n",
        "    \n",
        "    # Plot metrics vs threshold\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(metrics_df['threshold'], metrics_df['precision'], label='Precision')\n",
        "    plt.plot(metrics_df['threshold'], metrics_df['recall'], label='Recall')\n",
        "    plt.plot(metrics_df['threshold'], metrics_df['f1'], label='F1')\n",
        "    plt.xlabel('Classification Threshold')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Performance Metrics vs Classification Threshold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Run model performance analysis\n",
        "print(\"Analyzing model performance...\")\n",
        "plot_model_performance_comparison(results)\n",
        "plot_roc_curves(results, X_test, y_test)\n",
        "analyze_feature_importance(results, X.columns)\n",
        "analyze_prediction_thresholds(results, y_test)\n",
        "print(\"Model analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f5QtbHp3213Y"
      },
      "outputs": [],
      "source": [
        "def clean_and_preprocess(df):\n",
        "    \"\"\"Clean sentinel values, preprocess numerics, encode categoricals as int codes.\"\"\"\n",
        "    print(\"üßπ Cleaning and preprocessing data...\")\n",
        "\n",
        "    SENTINELS = {-1, -3, -7, -8, -9, -999, -9999, -99999,\n",
        "                 -999999, -9999999, -99999999, -999999999, -9999999999}\n",
        "\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.difference(['eid'])\n",
        "    df[numeric_cols] = df[numeric_cols].replace(list(SENTINELS), np.nan)\n",
        "    df[numeric_cols] = df[numeric_cols].mask(df[numeric_cols] < -1e8, np.nan)\n",
        "\n",
        "    if 'age' in df.columns:\n",
        "        df = df.query(\"40 <= age <= 69\").reset_index(drop=True)\n",
        "        print(f\"    After age filtering: {df.shape[0]} participants\")\n",
        "\n",
        "    # ------- NEW: keep categoricals as integer codes ----------\n",
        "    if 'sex' in df.columns:\n",
        "        df['sex'] = df['sex'].fillna(0).astype(int)                 # 0=Female, 1=Male\n",
        "\n",
        "    if 'smoking_status' in df.columns:\n",
        "        df['smoking_status'] = df['smoking_status'].fillna(3).astype(int)  # 3=Unknown\n",
        "\n",
        "    if 'alcohol_freq' in df.columns:\n",
        "        df['alcohol_freq'] = df['alcohol_freq'].fillna(0).astype(int)      # 0=Unknown\n",
        "    # ----------------------------------------------------------\n",
        "\n",
        "    if 'red_meat_intake' in df.columns:\n",
        "        redmeat_map = {0:0.0, 1:0.5, 2:1.0, 3:3.0, 4:5.5, 5:7.0}\n",
        "        df['red_meat_servings'] = df['red_meat_intake'].map(redmeat_map)\n",
        "        df['red_meat_missing']  = df['red_meat_intake'].isna().astype(int)\n",
        "\n",
        "    for col in ['moderate_mins', 'vigorous_mins']:\n",
        "        if col in df.columns:\n",
        "            df[f'{col}_missing'] = df[col].isna().astype(int)\n",
        "            df[col] = df[col].fillna(0)\n",
        "\n",
        "    print(f\"    ‚úÖ Data cleaned. Final shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_enhanced_features(df):\n",
        "    \"\"\"Enhanced feature engineering with lifestyle scores and PGS proxy\"\"\"\n",
        "    print(\"üîß Creating enhanced features...\")\n",
        "\n",
        "    # Lifestyle Score Components\n",
        "    lifestyle_score = 0\n",
        "\n",
        "    # BMI score (0-2 points)\n",
        "    if 'bmi' in df.columns:\n",
        "        bmi_filled = df['bmi'].fillna(df['bmi'].median())\n",
        "        df['bmi_score'] = np.where(bmi_filled < 25, 2,\n",
        "                         np.where(bmi_filled < 30, 1, 0))\n",
        "        lifestyle_score += df['bmi_score']\n",
        "\n",
        "    # Physical activity score (0-2 points)\n",
        "    if 'moderate_mins' in df.columns and 'vigorous_mins' in df.columns:\n",
        "        total_activity = df['moderate_mins'] + df['vigorous_mins'] * 2\n",
        "        df['activity_score'] = np.where(total_activity >= 150, 2,\n",
        "                              np.where(total_activity >= 75, 1, 0))\n",
        "        lifestyle_score += df['activity_score']\n",
        "\n",
        "    # Smoking score (0-2 points)\n",
        "    if 'smoking_status' in df.columns:\n",
        "        df['smoking_score'] = np.where(df['smoking_status'] == 0, 2,\n",
        "                             np.where(df['smoking_status'] == 1, 1, 0))\n",
        "        lifestyle_score += df['smoking_score']\n",
        "\n",
        "    # Diet score (0-2 points) - simplified\n",
        "    if 'fruit_intake' in df.columns and 'veg_intake' in df.columns:\n",
        "        fruit_filled = df['fruit_intake'].fillna(df['fruit_intake'].median())\n",
        "        veg_filled = df['veg_intake'].fillna(df['veg_intake'].median())\n",
        "        diet_score = (fruit_filled + veg_filled) / 2\n",
        "        df['diet_score'] = np.where(diet_score > df['fruit_intake'].median(), 2,\n",
        "                          np.where(diet_score > df['fruit_intake'].median() * 0.5, 1, 0))\n",
        "        lifestyle_score += df['diet_score']\n",
        "\n",
        "    # Sleep score (0-2 points)\n",
        "    if 'sleep_hrs' in df.columns:\n",
        "        sleep_filled = df['sleep_hrs'].fillna(df['sleep_hrs'].median())\n",
        "        df['sleep_score'] = np.where((sleep_filled >= 7) & (sleep_filled <= 9), 2,\n",
        "                           np.where((sleep_filled >= 6) & (sleep_filled <= 10), 1, 0))\n",
        "        lifestyle_score += df['sleep_score']\n",
        "\n",
        "    df['lifestyle_score'] = lifestyle_score\n",
        "\n",
        "    # Polygenic Risk Score proxy using PCs\n",
        "    pc_cols = [col for col in df.columns if col.startswith('PC')]\n",
        "    if len(pc_cols) >= 5:\n",
        "        # Create PGS proxy from first 5 PCs with random weights\n",
        "        np.random.seed(RANDOM_STATE)\n",
        "        weights = np.random.normal(0, 0.1, 5)\n",
        "        pgs_proxy = 0\n",
        "        for i, pc_col in enumerate(pc_cols[:5]):\n",
        "            if pc_col in df.columns:\n",
        "                pc_norm = df[pc_col].fillna(0) / (df[pc_col].std() + 1e-8)\n",
        "                pgs_proxy += pc_norm * weights[i]\n",
        "        df['pgs_proxy'] = pgs_proxy\n",
        "\n",
        "    # Age groups for fairness analysis\n",
        "    if 'age' in df.columns:\n",
        "        df['age_group'] = pd.cut(df['age'], bins=[40, 50, 60, 70],\n",
        "                                labels=['40-50', '50-60', '60-70'])\n",
        "\n",
        "    print(f\"    ‚úÖ Enhanced features created. Shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_target_variable(df, prevalence=0.07):\n",
        "    \"\"\"Create enhanced synthetic T2DM outcome\"\"\"\n",
        "    print(f\"üéØ Creating enhanced T2DM target variable (prevalence: {prevalence:.1%})\")\n",
        "\n",
        "    risk_score = np.zeros(len(df))\n",
        "\n",
        "    # Enhanced risk modeling\n",
        "    if 'age' in df.columns:\n",
        "        age_norm = (df['age'] - df['age'].mean()) / df['age'].std()\n",
        "        risk_score += age_norm * 0.8\n",
        "\n",
        "    if 'bmi' in df.columns:\n",
        "        bmi_filled = df['bmi'].fillna(df['bmi'].median())\n",
        "        risk_score += np.where(bmi_filled >= 30, 1.5, 0)\n",
        "        risk_score += np.where(bmi_filled >= 25, 0.8, 0)\n",
        "\n",
        "    if 'waist' in df.columns:\n",
        "        waist_filled = df['waist'].fillna(df['waist'].median())\n",
        "        risk_score += np.where(waist_filled > 102, 0.7, 0)\n",
        "        risk_score += np.where(waist_filled > 88, 0.5, 0)\n",
        "\n",
        "    # Use lifestyle score (protective)\n",
        "    if 'lifestyle_score' in df.columns:\n",
        "        lifestyle_norm = (df['lifestyle_score'] - df['lifestyle_score'].mean()) / df['lifestyle_score'].std()\n",
        "        risk_score -= lifestyle_norm * 0.6\n",
        "\n",
        "    # Use PGS proxy\n",
        "    if 'pgs_proxy' in df.columns:\n",
        "        risk_score += df['pgs_proxy'] * 0.4\n",
        "\n",
        "    if 'sex' in df.columns:\n",
        "        risk_score += np.where(df['sex'] == 'Male', 0.3, 0)\n",
        "\n",
        "    # Convert to probabilities\n",
        "    logits = risk_score * 1.5  # sharper separation for better distinction\n",
        "    probabilities = 1 / (1 + np.exp(-logits))\n",
        "\n",
        "    current_mean = probabilities.mean()\n",
        "    probabilities = probabilities * (prevalence / current_mean)\n",
        "    probabilities = np.clip(probabilities, 0.001, 0.999)\n",
        "\n",
        "    np.random.seed(RANDOM_STATE)\n",
        "    df['t2dm_event'] = np.random.binomial(1, probabilities)\n",
        "\n",
        "    actual_prevalence = df['t2dm_event'].mean()\n",
        "    print(f\"    ‚úÖ T2DM cases: {df['t2dm_event'].sum()}/{len(df)} ({actual_prevalence:.1%})\")\n",
        "\n",
        "    return df\n",
        "\n",
        "    def prepare_features(df):\n",
        "    # No age filtering here\n",
        "      df = df.copy()\n",
        "\n",
        "      # Drop rows with missing target or key features\n",
        "      df = df.dropna(subset=['age'])\n",
        "\n",
        "      # Age binning (optional)\n",
        "      df['age_bin'] = pd.cut(df['age'], bins=[0, 30, 40, 50, 60, 70, 80, 100], labels=False)\n",
        "\n",
        "      # Identify feature types\n",
        "      numeric_features = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "      numeric_features = [col for col in numeric_features if col not in ['T2DM', 'age']]\n",
        "      categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist() + ['age_bin']\n",
        "\n",
        "      # Pipelines\n",
        "      numeric_transformer = Pipeline(steps=[\n",
        "          ('imputer', SimpleImputer(strategy='median')),\n",
        "          ('scaler', StandardScaler())\n",
        "      ])\n",
        "      categorical_transformer = Pipeline(steps=[\n",
        "          ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "          ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "      ])\n",
        "\n",
        "      preprocessor = ColumnTransformer(\n",
        "          transformers=[\n",
        "              ('num', numeric_transformer, numeric_features),\n",
        "              ('cat', categorical_transformer, categorical_features)\n",
        "          ])\n",
        "\n",
        "      X = df.drop(columns=['T2DM'])\n",
        "      y = df['T2DM']\n",
        "\n",
        "      return X, y, preprocessor\n",
        "\n",
        "\n",
        "\n",
        "def prepare_features_enhanced(df):\n",
        "    \"\"\"Enhanced feature preparation with PCA\"\"\"\n",
        "    print(\"üîß Preparing enhanced features...\")\n",
        "\n",
        "    if 't2dm_event' not in df.columns:\n",
        "        df = create_target_variable(df)\n",
        "\n",
        "    y = df['t2dm_event']\n",
        "    exclude_cols = ['eid', 't2dm_event', 'age_group']\n",
        "    X = df.drop(columns=exclude_cols)\n",
        "\n",
        "    # mark categorical int columns\n",
        "    cat_int_cols = ['sex', 'smoking_status', 'alcohol_freq']\n",
        "\n",
        "    # treat everything (including int-coded cats) as numeric for modelling\n",
        "    numeric_features = list(X.columns)\n",
        "    categorical_features = cat_int_cols             # for SMOTENC only\n",
        "\n",
        "    print(f\"    üìä Numeric features ({len(numeric_features)}) \"\n",
        "          f\"| SMOTENC categorical ints ({len(categorical_features)})\")\n",
        "    return X, y, numeric_features, categorical_features, df.get('age_group')\n",
        "\n",
        "def create_preprocessing_pipeline_enhanced(numeric_features, _categorical_unused):\n",
        "    \"\"\"Simple numeric pipeline (+ optional PCA for PCs).\"\"\"\n",
        "    print(\"‚öôÔ∏è Creating enhanced preprocessing pipeline...\")\n",
        "\n",
        "    pc_features    = [c for c in numeric_features if c.startswith('PC')]\n",
        "    other_numeric  = [c for c in numeric_features if c not in pc_features]\n",
        "\n",
        "    pc_pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler',  StandardScaler()),\n",
        "        ('pca',     PCA(n_components=min(10, len(pc_features)), random_state=RANDOM_STATE))\n",
        "    ]) if pc_features else None\n",
        "\n",
        "    num_pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler',  StandardScaler())\n",
        "    ])\n",
        "\n",
        "    transformers = [('num', num_pipe, other_numeric)]\n",
        "    if pc_pipe:\n",
        "        transformers.append(('pc', pc_pipe, pc_features))\n",
        "\n",
        "    return ColumnTransformer(transformers)\n",
        "\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from collections import Counter\n",
        "\n",
        "def train_enhanced_models(X, y, preprocessor, age_groups=None):\n",
        "    print(\"üöÄ Training enhanced ensemble models...\")\n",
        "\n",
        "    # split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
        "\n",
        "    # int-coded categorical indices for SMOTENC\n",
        "    cat_cols = ['sex', 'smoking_status', 'alcohol_freq']\n",
        "    cat_idx  = [i for i, c in enumerate(X.columns) if c in cat_cols]\n",
        "\n",
        "    # encode NaNs to sentinel for SMOTENC\n",
        "    X_train_sm = X_train.fillna(-999)\n",
        "    X_test_sm  = X_test.fillna(-999)\n",
        "\n",
        "    smote = SMOTENC(categorical_features=cat_idx, random_state=RANDOM_STATE)\n",
        "\n",
        "    models = {\n",
        "    # ‚ñ∏ Linear baseline\n",
        "    'LogReg': LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced',\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "\n",
        "    # ‚ñ∏ Classical tree\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=12,\n",
        "        min_samples_split=10,\n",
        "        class_weight='balanced',\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "\n",
        "    # ‚ñ∏ Gradient-boosted trees (LightGBM)\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        # -- GPU acceleration if your Colab has it and LightGBM-GPU is installed\n",
        "        #    comment out device='gpu' if your build is CPU-only\n",
        "        device='gpu',\n",
        "        boosting_type='gbdt',\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=-1,\n",
        "        num_leaves=64,\n",
        "        class_weight='balanced',\n",
        "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "\n",
        "    # ‚ñ∏ GPU-accelerated XGBoost\n",
        "    'XGB': xgb.XGBClassifier(\n",
        "        tree_method='gpu_hist',\n",
        "        predictor='gpu_predictor',\n",
        "        gpu_id=0,\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
        "        eval_metric='logloss',\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    }\n",
        "    results = {}\n",
        "    for name, clf in models.items():\n",
        "        print(f\"\\nüìà {name}\")\n",
        "        pipe = ImbPipeline([\n",
        "            ('smote', smote),\n",
        "            ('prep',  preprocessor),\n",
        "            ('clf',   clf)\n",
        "        ])\n",
        "        pipe.fit(X_train_sm, y_train)\n",
        "\n",
        "        prob = pipe.predict_proba(X_test_sm)[:,1]\n",
        "        pred = (prob >= 0.15).astype(int)\n",
        "        results[name] = {\n",
        "              'pipeline': pipe,\n",
        "              'auc': roc_auc_score(y_test, prob),\n",
        "              'f1' : f1_score(y_test, pred),\n",
        "              'prob': prob,\n",
        "              'pred': pred\n",
        "          }\n",
        "        print(f\"    AUC={results[name]['auc']:.3f} | F1={results[name]['f1']:.3f}\")\n",
        "\n",
        "    return results, X_test_sm, y_test\n",
        "\n",
        "def decode_column(series, col_name):\n",
        "    \"\"\"Convert int codes back to readable labels for plots.\"\"\"\n",
        "    return series.map(CATEGORY_MAPPINGS[col_name]).astype('category')\n",
        "\n",
        "def evaluate_fairness(results, X_test, y_test, age_groups=None):\n",
        "    \"\"\"Basic fairness evaluation across demographics\"\"\"\n",
        "    print(\"\\n‚öñÔ∏è Evaluating model fairness...\")\n",
        "\n",
        "    if age_groups is None:\n",
        "        print(\"    No demographic data available for fairness analysis\")\n",
        "        return\n",
        "\n",
        "    best_model_name = max(results.keys(), key=lambda k: results[k]['auc_roc'])\n",
        "    best_model_results = results[best_model_name]\n",
        "    y_pred_proba = best_model_results['y_pred_proba']\n",
        "\n",
        "    print(f\"\\n    Fairness analysis for best model: {best_model_name}\")\n",
        "\n",
        "    # Group-wise performance\n",
        "    for group in age_groups.unique():\n",
        "        if pd.isna(group):\n",
        "            continue\n",
        "        mask = age_groups == group\n",
        "        if mask.sum() < 10:  # Skip small groups\n",
        "            continue\n",
        "\n",
        "        group_auc = roc_auc_score(y_test[mask], y_pred_proba[mask])\n",
        "        group_prev = y_test[mask].mean()\n",
        "\n",
        "        print(f\"    {group}: AUC-ROC = {group_auc:.3f}, Prevalence = {group_prev:.1%}, N = {mask.sum()}\")\n",
        "\n",
        "def basic_shap_analysis(results, X_train, X_test, feature_names=None):\n",
        "    \"\"\"Basic SHAP analysis for interpretability\"\"\"\n",
        "    print(\"\\nüîç Performing basic SHAP analysis...\")\n",
        "\n",
        "    try:\n",
        "        # Get best model\n",
        "        best_model_name = max(results.keys(), key=lambda k: results[k]['auc_roc'])\n",
        "        best_pipeline = results[best_model_name]['pipeline']\n",
        "\n",
        "        print(f\"    Analyzing {best_model_name}...\")\n",
        "\n",
        "        # Transform data for SHAP\n",
        "        X_train_transformed = best_pipeline.named_steps['base_estimator'].named_steps['preprocessor'].transform(X_train[:1000])  # Sample for speed\n",
        "        X_test_transformed = best_pipeline.named_steps['base_estimator'].named_steps['preprocessor'].transform(X_test[:100])\n",
        "\n",
        "        # Get the actual classifier\n",
        "        classifier = best_pipeline.named_steps['base_estimator'].named_steps['classifier']\n",
        "\n",
        "        # Create SHAP explainer (basic)\n",
        "        if hasattr(classifier, 'predict_proba'):\n",
        "            explainer = shap.Explainer(classifier.predict_proba, X_train_transformed)\n",
        "            shap_values = explainer(X_test_transformed)\n",
        "\n",
        "            # Basic summary\n",
        "            print(f\"    ‚úÖ SHAP analysis completed for {X_test_transformed.shape[0]} samples\")\n",
        "            print(f\"    Feature importance calculated with {X_train_transformed.shape[1]} features\")\n",
        "\n",
        "        else:\n",
        "            print(\"    ‚ö†Ô∏è  SHAP analysis not supported for this model type\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ö†Ô∏è  SHAP analysis failed: {str(e)[:100]}...\")\n",
        "\n",
        "def plot_calibration_curve(results, y_test):\n",
        "    \"\"\"Plot calibration curves for model comparison\"\"\"\n",
        "    print(\"\\nüìä Plotting calibration curves...\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for name, result in results.items():\n",
        "        y_pred_proba = result['y_pred_proba']\n",
        "        fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "            y_test, y_pred_proba, n_bins=10\n",
        "        )\n",
        "\n",
        "        plt.plot(mean_predicted_value, fraction_of_positives,\n",
        "                marker='o', label=f\"{name} (Brier: {result['brier_score']:.3f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "    plt.xlabel('Mean Predicted Probability')\n",
        "    plt.ylabel('Fraction of Positives')\n",
        "    plt.title('Calibration Curves - T2DM Prediction Models')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8TyxDUVR5WVe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xbC9UY9B5WR3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-ADg3Zf25WPO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9ZOTTXxy22DV"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Enhanced main execution function\"\"\"\n",
        "    print(\"üè• Enhanced Type 2 Diabetes Prediction Pipeline\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Load and process data\n",
        "        df = load_and_process_data()\n",
        "        df = clean_and_preprocess(df)\n",
        "\n",
        "        # Enhanced feature engineering\n",
        "        df = create_enhanced_features(df)\n",
        "        df = create_target_variable(df)\n",
        "        print(\"\\nüîç Sample of cleaned data:\")\n",
        "        display(df.head())\n",
        "\n",
        "        print(\"\\nüìä Class distribution preview:\")\n",
        "        print(df['t2dm_event'].value_counts(normalize=True).rename({0: 'Non-T2DM', 1: 'T2DM'}).round(3))\n",
        "\n",
        "\n",
        "        # Enhanced feature preparation\n",
        "        X, y, numeric_features, categorical_features, age_groups = prepare_features_enhanced(df)\n",
        "\n",
        "        # Enhanced preprocessing\n",
        "        preprocessor = create_preprocessing_pipeline_enhanced(numeric_features, categorical_features)\n",
        "\n",
        "        # Enhanced model training\n",
        "        results, X_train, X_test, y_train, y_test, age_test = train_enhanced_models(\n",
        "            X, y, preprocessor, age_groups\n",
        "        )\n",
        "\n",
        "        # Enhanced evaluation\n",
        "        print(\"\\nüéâ Enhanced pipeline completed successfully!\")\n",
        "        print(\"\\nüìä Enhanced Model Performance Summary:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for name, result in results.items():\n",
        "            print(f\"{name}:\")\n",
        "            print(f\"  AUC-ROC: {result['auc_roc']:.3f}\")\n",
        "            print(f\"  AUC-PR:  {result['auc_pr']:.3f}\")\n",
        "            print(f\"  F1-Score: {result['f1_score']:.3f}\")\n",
        "            print(f\"  Brier Score: {result['brier_score']:.3f}\")\n",
        "            print()\n",
        "\n",
        "        # Fairness evaluation\n",
        "        evaluate_fairness(results, X_test, y_test, age_test)\n",
        "\n",
        "        # Basic interpretability\n",
        "        basic_shap_analysis(results, X_train, X_test)\n",
        "\n",
        "        # Calibration analysis\n",
        "        plot_calibration_curve(results, y_test)\n",
        "\n",
        "        return df, results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in enhanced pipeline: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xjlZtA-wZZ7S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zzz-lW4122GQ",
        "outputId": "d00b5ab2-d647-4464-e2af-8c69124be4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üè• Enhanced Type 2 Diabetes Prediction Pipeline\n",
            "============================================================\n",
            "üìà Loading and processing data...\n",
            "    ‚úÖ Processed integer_no_arrays.tsv: (600000, 10)\n",
            "    ‚úÖ Processed real_fields1.tsv: (600000, 42)\n",
            "üìä Combined dataset shape: (600000, 53)\n",
            "üßπ Cleaning and preprocessing data...\n",
            "    After age filtering: 360244 participants\n",
            "    ‚úÖ Data cleaned. Final shape: (360244, 57)\n",
            "üîß Creating enhanced features...\n",
            "    ‚úÖ Enhanced features created. Shape: (360244, 65)\n",
            "üéØ Creating enhanced T2DM target variable (prevalence: 7.0%)\n",
            "    ‚úÖ T2DM cases: 25084/360244 (7.0%)\n",
            "\n",
            "üîç Sample of cleaned data:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ecf5ce1b-bc77-4ea3-9dad-8110fd65e396\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eid</th>\n",
              "      <th>sex</th>\n",
              "      <th>moderate_mins</th>\n",
              "      <th>vigorous_mins</th>\n",
              "      <th>sleep_hrs</th>\n",
              "      <th>fruit_intake</th>\n",
              "      <th>veg_intake</th>\n",
              "      <th>red_meat_intake</th>\n",
              "      <th>alcohol_freq</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>...</th>\n",
              "      <th>vigorous_mins_missing</th>\n",
              "      <th>bmi_score</th>\n",
              "      <th>activity_score</th>\n",
              "      <th>smoking_score</th>\n",
              "      <th>diet_score</th>\n",
              "      <th>sleep_score</th>\n",
              "      <th>lifestyle_score</th>\n",
              "      <th>pgs_proxy</th>\n",
              "      <th>age_group</th>\n",
              "      <th>t2dm_event</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000016</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.374418</td>\n",
              "      <td>50-60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000048</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.055388</td>\n",
              "      <td>40-50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000059</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.277568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000063</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.073158</td>\n",
              "      <td>50-60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000080</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.166802</td>\n",
              "      <td>60-70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 66 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecf5ce1b-bc77-4ea3-9dad-8110fd65e396')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ecf5ce1b-bc77-4ea3-9dad-8110fd65e396 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ecf5ce1b-bc77-4ea3-9dad-8110fd65e396');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-02a66d25-3bbb-4078-86a2-e7b23b6740d6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02a66d25-3bbb-4078-86a2-e7b23b6740d6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-02a66d25-3bbb-4078-86a2-e7b23b6740d6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       eid  sex  moderate_mins  vigorous_mins  sleep_hrs  fruit_intake  \\\n",
              "0  1000016    1            0.0           83.0       20.0          44.0   \n",
              "1  1000048    0            4.0          480.0        8.0           6.0   \n",
              "2  1000059    0            0.0           35.0        9.0          22.0   \n",
              "3  1000063    0           -2.0          269.0        6.0          44.0   \n",
              "4  1000080    0            1.0          610.0       17.0          15.0   \n",
              "\n",
              "   veg_intake  red_meat_intake  alcohol_freq  smoking_status  ...  \\\n",
              "0        40.0              NaN             6               3  ...   \n",
              "1        24.0              NaN             1               2  ...   \n",
              "2         1.0              NaN             1               3  ...   \n",
              "3         7.0              NaN             3               2  ...   \n",
              "4       100.0              NaN             5               3  ...   \n",
              "\n",
              "   vigorous_mins_missing  bmi_score  activity_score  smoking_score  \\\n",
              "0                      0          2               2              0   \n",
              "1                      0          1               2              0   \n",
              "2                      0          1               0              0   \n",
              "3                      0          1               2              0   \n",
              "4                      0          1               2              0   \n",
              "\n",
              "   diet_score  sleep_score  lifestyle_score  pgs_proxy  age_group  t2dm_event  \n",
              "0           2            0                6   0.374418      50-60           0  \n",
              "1           1            2                6  -0.055388      40-50           1  \n",
              "2           1            2                4  -0.277568        NaN           0  \n",
              "3           2            1                6  -0.073158      50-60           0  \n",
              "4           2            0                5   0.166802      60-70           0  \n",
              "\n",
              "[5 rows x 66 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Class distribution preview:\n",
            "t2dm_event\n",
            "Non-T2DM    0.93\n",
            "T2DM        0.07\n",
            "Name: proportion, dtype: float64\n",
            "üîß Preparing enhanced features...\n",
            "    üìä Numeric features (63) | SMOTENC categorical ints (3)\n",
            "‚öôÔ∏è Creating enhanced preprocessing pipeline...\n",
            "üöÄ Training enhanced ensemble models...\n",
            "\n",
            "üìà LogReg\n",
            "    AUC=0.580 | F1=0.144\n",
            "\n",
            "üìà RandomForest\n",
            "    AUC=0.593 | F1=0.150\n",
            "\n",
            "üìà LightGBM\n",
            "[LightGBM] [Info] Number of positive: 268128, number of negative: 268128\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 5185\n",
            "[LightGBM] [Info] Number of data points in the train set: 536256, number of used features: 33\n",
            "[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-40GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 27 dense feature groups (14.32 MB) transferred to GPU in 0.014335 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "    AUC=0.606 | F1=0.138\n",
            "\n",
            "üìà XGB\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the enhanced pipeline\n",
        "    data, model_results = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM55DqoZU9ES"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
